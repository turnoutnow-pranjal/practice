Hola y bienvenido a elegir la base de datos adecuada para las aplicaciones modernas como parte de nuestra serie en línea adicional de West Summit. Mi nombre es William Wong y soy un arquitecto especializado en soluciones de bases de datos. Y hoy me acompañará Michael Riccardi, nuestro arquitecto especializado en soluciones de desarrollo. Hoy. Estamos muy contentos de estar aquí para mostrarle cómo se pueden utilizar las bases de datos especialmente diseñadas para mejorar la escala, el rendimiento y la disponibilidad de sus aplicaciones. Nuestra agenda incluirá una introducción a los requisitos de las aplicaciones modernas. A continuación, analizaremos los desafíos que se resuelven mediante microservicios y bases de datos especialmente diseñadas antes de analizar cómo podemos elegir las bases de datos adecuadas para sus cargas de trabajo particulares. Miguel. A continuación, profundizaremos un poco más, donde modernizará una aplicación de una pila de bases de datos relacionales monolíticas a la que utilizará bases de datos especialmente diseñadas y le mostrará las diferencias tanto en el rendimiento como en la escala. Así que comencemos y veamos los requisitos de nuestras aplicaciones modernas. Y primero analizamos las aplicaciones que cada uno usa todos los días, como nuestros viajes compartidos, los medios de comunicación, el streaming, la banca, los juegos y las redes sociales. Empezamos a ver algunos patrones comunes. Estos patrones podrían ser que millones de usuarios accedan a nuestras aplicaciones en diferentes geografías. Y estos mismos usuarios esperan experiencias instantáneas que podrían reducirse a tiempos de respuesta consistentes en milisegundos o incluso inferiores a un milisegundo. Nuestras aplicaciones deberán hiperescalar para satisfacer las demandas de eventos como nuestras ventas flash o el procesamiento de orina, y luego reducirlas. No estamos en uso para poder minimizar los costos. Se prevé que capturará más datos en los próximos tres años que en los últimos 30 años. Y esto necesitará herramientas especializadas para procesar los petabytes. Si no es un valor de cero bytes de datos estructurados y no estructurados. Si nos tomamos un tiempo ahora y pensamos en los patrones arquitectónicos de la mayoría de estas aplicaciones basadas en la nube, descubrirá que todas son microservicios. Esto significa que están altamente distribuidas, están poco acopladas y se accede a ellas a través de un P.I.S. Entonces, ¿qué significa ese cambio en la arquitectura para nuestra base de datos subyacente? Nuestras aplicaciones ahora están desacopladas en servicios. Permite que cada uno de estos servicios tenga su propia base de datos independiente. Y eso nos aportará muchas ventajas, por ejemplo, nos permitirá escalar nuestras aplicaciones a medida que cada canal de servicio y base de datos se amplíe de forma independiente. Tomemos el Black Friday como caso de uso. Es posible que necesitemos ampliar nuestro catálogo y servicio de pago a cientos de miles de solicitudes simultáneas en un período de tiempo breve, pero es posible que nuestros registros de usuarios no crezcan en la misma medida. Otro beneficio es la agilidad añadida. Ya que ahora podemos innovar más rápido en diferentes componentes. Podemos probar y deshacer rápidamente nuevas versiones y funciones a nivel modular sin tener que ocuparnos de todas las complejas dependencias acopladas que están relacionadas con los monolitos. Un desafío empresarial común es aumentar la disponibilidad de nuestras aplicaciones y, al desvincular nuestras bases de datos, aumentará su disponibilidad general, ya que ya no tenemos una base de datos monolítica que sirva de único punto de contención para nuestros eventos, como las implementaciones de código o las actualizaciones y los parches. Ahora que entendemos las ventajas de desvincular nuestros datos. ¿Por qué consideraríamos bases de datos especialmente diseñadas para nuestros microservicios? Nuestros desarrolladores desean la base de datos adecuada para satisfacer las necesidades de nuestras aplicaciones modernas, tal como describimos anteriormente. Y, francamente, ese enfoque único de usar una base de datos relacional para todo, simplemente ya no funciona. Por ejemplo, es posible que necesitemos una base de datos que proporcione tiempos de respuesta con una latencia de microsegundos para poder renderizar rápidamente nuestros sitios web o ofrecer tiempos de respuesta consistentes para satisfacer las demandas de los usuarios del cirujano. Y la arquitectura relacional no es la más adecuada para estos casos de uso particulares. De hecho, no utilizar la base de datos correcta suele provocar problemas de rendimiento, falta de escalabilidad, falta de flexibilidad para los desarrolladores y un aumento de nuestros costes generales. Por lo general, cuando hablo con mis clientes, es un obstáculo para adoptar estas bases de datos especialmente diseñadas con posibles gastos operativos. Y esto incluyó inversiones en hardware y software iniciales o experiencia para hacerlos escalables, de alta disponibilidad y de alto rendimiento. Y aquí es donde entra en juego el aws. Ofreceremos la cartera más amplia y completa de más de 15 bases de datos especialmente diseñadas que pueden respaldar los diferentes modelos de datos al aprovechar las bases de datos diseñadas específicamente y totalmente administradas que creamos desde cero, los clientes ahora pueden ahorrar tiempo y costos, mejorar el rendimiento a escala e innovar más rápido. Hemos creado bases de datos especialmente diseñadas para adaptarse a cada caso de uso, como el documento de valores clave relacionales en la memoria, el libro de series temporales de columnas anchas y nuestras bases de datos de gráficos Ahora que entendemos la necesidad de crear bases de datos especialmente diseñadas, ¿cómo seleccionaría las bases de datos adecuadas para sus casos de uso particulares? Lo que me gustaría decirle a la gente es que, en lugar de mirar una lista de 100 bases de datos diferentes, ¿por qué no empezamos pensando en las categorías de bases de datos comunes? Así que ahora analizamos rápidamente las categorías. No solo encontrará esa conocida base de datos relacional a la izquierda, sino que también verá otras bases de datos, bases de datos como nuestra base de datos de documentos de Amazon, que está optimizada para almacenar los datos en formato Jason. Y dado que no es una base de datos secuela, nos dará esa flexibilidad a la hora de cambiar los esquemas de las aplicaciones, pero también nos permitirá consultar documentos en función de cualquier atributo. Y esto es muy útil para nuestras aplicaciones móviles o de administración de contenido o para una base de datos de gráficos como Amazon Neptune, que nos permite trabajar con conjuntos de datos altamente conectados. Podemos intentar modelar esto en una base de datos relacional con articulaciones complicadas y consultas anidadas, pero nuestra latencia aumentará a medida que aumenten varias de nuestras relaciones en las bases de datos de gráficos. Sin embargo, nos permite atravesar millones de relaciones en segundos, lo que es ideal para la detección de fraudes, las redes sociales y nuestros motores de recomendación. Por último, como una base de datos de series temporales como nuestra secuencia temporal de Amazon, que está optimizada para ingerir billones de datos de secuencias de tiempo al día y nos brinda funciones basadas en el tiempo, como la correlación y la interpolación, para que podamos obtener una mejor visión de esos datos. Y esto es ideal para nuestras aplicaciones de desarrollo o seguimiento de eventos de IOT. Ahora dediquemos un tiempo a profundizar un poco más en algunas categorías muy comunes que he visto entre mis clientes. Empecemos con un modelo de datos relacionales muy conocido, los datos relacionales están muy estructurados y los datos se dividen en tablas, y las relaciones que impone el sistema son claves principales y referenciales, y los buenos casos de uso para ellos serán las cargas de trabajo en las que no podemos predefinir todos nuestros patrones de acceso front o si tuviéramos aplicaciones que requieran una alta integridad referencial y una gran consistencia. Al igual que con nuestros sistemas de pago en línea. Una base de datos nativa de la nube que podemos elegir para nuestros modelos relacionales es Amazon Arora. Arora es compatible tanto con mi secuela como con Postgres y puede ayudarnos a mejorar nuestro rendimiento al proporcionar hasta cinco veces más rendimiento que el estándar. Mi secuela y tres veces más que la de Postgres estándar. Nos ayudará a escalar automáticamente los recursos informáticos y de almacenamiento, y dibujamos a Billy para que almacenara nuestros datos de seis maneras en tres zonas de disponibilidad. Y dado que se trata de un servicio gestionado, permitirá automatizar tareas como la implementación y el aprovisionamiento, la aplicación periódica de parches y actualizaciones, las copias de seguridad y nos proporcionará funciones de seguridad, como el cifrado en tránsito y en reposo. Otra gran categoría. Para ver nuestras bases de datos de valores clave. Los datos de valores clave son aquellos que utilizan ese sencillo método de valores clave para almacenar y recuperar datos, y su fortaleza radica en su diseño para particionar o particionar datos en gran medida y luego almacenarlos físicamente en función de esa clave de partición. Ese diseño le permite escalar horizontalmente a prácticamente cualquier tamaño y, al mismo tiempo, nos brinda tiempos de respuesta consistentes, independientemente de la escala. Así que veamos un caso de uso de un juego en línea que necesita almacenar los datos de sesión de un usuario y tiene un patrón de acceso definido a través de la etiqueta de jugador para recuperar ese conjunto de datos. Como se trata de un juego en línea, queremos garantizar una experiencia uniforme para el jugador, independientemente de si había 10 o incluso 100 000 usuarios. Si el juego despega en este caso de uso en particular, utilizaremos una base de datos de valores clave para lograr tiempos de respuesta consistentes, independientemente del crecimiento de la aplicación. Una base de datos especialmente diseñada que podemos elegir para nuestras bases de datos de valores clave es amazon dynamodb. Está totalmente gestionado y sin servidor, lo que significa que se encargará de todo el software de aprovisionamiento, de los parches de seguridad y, para ayudarnos a escalar automáticamente, dynamodb nos permite crear aplicaciones que puedan proporcionar tiempos de respuesta de un solo dígito en milisegundos a gran escala y para nuestras aplicaciones de misión crítica que podríamos usar a nivel mundial. replicación para replicar nuestros conjuntos de datos en varias regiones. Una categoría muy popular entre mis clientes son las bases de datos de memoria. Las bases de datos de memoria almacenan nuestros datos en la memoria en lugar de en esta, lo que nos da tiempos de respuesta inferiores a los milisegundos. Y esto es ideal para los casos de uso para almacenar los datos de la sesión de un usuario para mantener una tabla de clasificación para juegos en línea o modelos de aprendizaje automático de entrenamiento. Pero el caso de uso más común que he visto entre mis clientes se coloca aquí como dinero en efectivo frente a nuestras bases de datos relacionales. Esto nos dará tiempos de respuesta mucho mejores para nuestros usuarios finales y aliviará las presiones de escalado de lectura en la base de datos relacional subyacente, lo que puede provocar problemas de estabilidad y contención de recursos, como Makayla le mostrará en su siguiente demostración para bases de datos en memoria. Tenemos la opción de Amazon Elastic Cache. Es un servicio totalmente gestionado que nos permite ofrecer tiempos de respuesta inferiores a un milisegundo y un escalado sin interrupciones. Ambos son compatibles con la memoria caché. DM Reedus y las personas que lo usaban para la caché de memorias normalmente lo usaban para crear capas de cationes escalables simples para sus aplicaciones sensibles a la latencia, mientras que nuestros usuarios de Reddit lo usarán para casos de uso más versátiles, como para juegos, análisis en tiempo real y aprendizaje automático con regis. También tenemos la opción de Amazon Memory Day Bay, que es un clúster totalmente administrado con durabilidad. El debate sobre la memoria nos proporciona un rendimiento ultrarrápido con total compatibilidad con los registros de código abierto, lo que nos permite utilizar todo esto en estructuras de datos ricas, como conjuntos ordenados para tablas de clasificación en línea, mediante el aprovechamiento. Un registro de transacciones distribuido en todas las zonas de disponibilidad. Memory DB nos proporciona una recuperación rápida de la base de datos y los reinicia sin riesgo de pérdida de datos, lo que significa que ahora podemos utilizarla como nuestra base de datos principal para conjuntos de datos persistentes. Ahora que entendemos la necesidad y los beneficios de una arquitectura de base de datos desacoplada, hemos analizado algunos casos de uso que las bases de datos especialmente diseñadas resuelven. Me gustaría presentarles a Michaeli, quien puso todo esto en práctica en forma de una demostración para Michael. Gracias William. En esta demostración veremos mascotas increíbles, awesome pets es una empresa ficticia y en este escenario inventado, awesome pets es una tienda de mascotas en línea, awesome pets tiene todas las características de una tienda de comercio electrónico donde puedes navegar por el catálogo, añadir artículos a la cesta y ver la tecnología actual de awesome pets La pila consiste en un backend monolítico heredado y un monolítico. Mi base de datos de secuelas. Esta aplicación monolítica potencia todas las diferentes características y funcionalidades de las increíbles mascotas. Awesome pets se enfrenta a una serie de desafíos con sus monolitos heredados. En primer lugar, han descubierto que algunas consultas son extremadamente lentas, especialmente en casos de alta carga. Luego, como resultado de que cada consulta se vuelve cada vez más lenta durante los picos de tráfico, las solicitudes de los usuarios fallan y los usuarios no pueden completar las transacciones. Por último, la base de datos se queda sin recursos y sin el Señor, lo que puede provocar que la base de datos se bloquee y que toda la aplicación no esté disponible. Si también está intentando escalar aplicaciones monolíticas. Estos desafíos pueden resultarle muy familiares. Así que ahora te mostraré cómo funciona la aplicación Legacy Amazing Pets realizando una sencilla prueba. Luego te mostraré cómo se pueden desvincular las increíbles mascotas con microservicios y bases de datos especialmente diseñadas. Cómo elegir la base de datos adecuada para el trabajo correcto y mostrarle las diferencias de rendimiento entre la aplicación monolítica heredada y la aplicación de microservicios. Por último, abordaré brevemente algunos de los patrones de diseño utilizados en la nueva arquitectura. Permítanme comenzar mostrándoles un ejemplo de viaje de usuario sobre mascotas increíbles. Como puedes ver aquí cuando visito mascotas increíbles. Se me presenta el catálogo de mascotas. El catálogo muestra los tipos de mascotas disponibles en el comentario y la cuenta de cada tipo. Puedo añadir mascotas al carrito haciendo clic en el botón de añadir al carrito y, una vez que haya añadido todas las mascotas, puedo echar un vistazo a la tarjeta y proceder al pago. En la página de pago. Puedo introducir todos los detalles necesarios para completar la transacción y confirmar el pago y, una vez que aparezca el mensaje de confirmación, el recorrido del usuario estará completo. Ahora ejecutemos la prueba de carga para ver cómo funciona la aplicación monolítica en la carga. Hay muchas herramientas disponibles para realizar pruebas de rendimiento, como el metro j o la artillería. Para nombrar unos pocos. Pero para esta demostración, voy a usar Blaze Meter. Esta prueba simula un viaje de usuario real con mascotas increíbles, en el que cada usuario obtiene un catálogo de un artículo en el carrito y envía otro. Esta prueba está configurada con un total de 50 usuarios simultáneos navegando a lo largo del viaje durante 10 minutos y el número de usuarios aumentará gradualmente a lo largo de un minuto. Por último, esta prueba se realizará en la región de AWS Oregon. Ahora comenzaré la prueba de carga y, como la prueba tarda unos 10 minutos en completarse, aceleraré el vídeo y veremos los resultados una vez finalizada la prueba. Así que la prueba ya está completa y podemos ver los resultados en estas pantallas, tenemos dos gráficos. El de la izquierda muestra cuántas solicitudes se han realizado correctamente durante la prueba y cuántas solicitudes fallaron. Y el gráfico de la derecha muestra el tiempo de respuesta promedio a lo largo de la prueba. Si nos centramos en el gráfico de la derecha, podemos ver que a medida que aumenta el número de usuarios, el tiempo medio de respuesta de la aplicación sigue aumentando, alcanzando un tiempo máximo de respuesta de unos siete segundos. Y en algún momento, los tiempos de respuesta se redujeron drásticamente a solo unos cientos de milisegundos y, después de unos minutos, el tiempo de respuesta vuelve a subir a siete segundos. Si observamos el gráfico de la izquierda, queda claro por qué hay una caída en el tiempo de respuesta alrededor de 1750. Podemos ver que, en este momento, casi todas las solicitudes fallan y no hay solicitudes exitosas. Esto nos indica que el sitio web estuvo inactivo durante ese tiempo y que la solicitud del usuario falló muy rápidamente. Así que profundicemos un poco más para ver cuál es la causa de estos problemas. Estoy usando AWS X ray, que es un servicio de rastreo para profundizar en la solicitud fallida del mapa de servicios de rayos X. Puedo ver mi aplicación monolítica y las solicitudes que van a la base de datos. El color rojo aquí representa la cantidad de solicitudes que han fallado en la base de datos. Ahora voy a utilizar X ray Insights. AWS X Ray Insights identifica en qué parte de las aplicaciones se producen los problemas, los registros de cada problema y el impacto asociado. Y cuando abro una información, puedo ver inmediatamente cuál es la causa principal del problema y el impacto que está teniendo. En este caso, me dice que el 23% de la solicitud falló en la base de datos. Luego puedo hacer clic en Analizar información para profundizar en cada solicitud individual fallida. Una vez que he abierto una solicitud fallida, puedo ver todos los componentes que se ejecutaron para esta solicitud, así como el tiempo que tardó cada uno de ellos. En este caso específico, la base de datos devolvió un error después de 17 segundos debido a un bloqueo. Por último, echemos un vistazo a las métricas basadas en datos para entender con más detalle lo que ocurrió. Si nos centramos en la utilización de la CPU, podemos ver que la utilización de la CPU de la base de datos aumenta hasta un 100% muy rápidamente y, después de unos minutos de utilización sostenida del 100% de la CPU, la utilización de la IP de la base de datos vuelve al 0% y, a continuación, vuelve al 100%. Esto se debe a que la base de datos se bloquea y se reinicia debido al uso elevado de la CPU También puedes validarlo consultando otras métricas, como la I correcta y las conexiones a bases de datos. Como hemos visto, esta aplicación antigua no funciona bien, las solicitudes pueden tardar hasta 10 segundos durante los picos de tráfico y la base de datos se bloquea y provoca interrupciones. Increíbles mascotas podrían considerar la posibilidad de implementar muchas de las optimizaciones comunes para aplicaciones monolíticas. Sin embargo, esperan crecer 10 veces durante el próximo año y saben que, incluso con las optimizaciones comunes para las aplicaciones monolíticas, no podrán soportar el crecimiento planificado. Esta es la razón por la que las mascotas increíbles decidieron pasar a los microservicios con bases de datos especialmente diseñadas. Así que tratemos de entender cómo descomponen esta aplicación, cómo decidieron qué base de datos utilizar para cada caso de uso en esta nueva arquitectura, awesome pets se divide en cuatro microservicios, el inventario, el carrito de pedidos y el catálogo del inventario. El servicio Micro usa dynamodb. Los datos del inventario se pueden almacenar en un formato de valores clave simple y hay un patrón bien definido, como añadir o eliminar mascotas al inventario. Luego tenemos el procesamiento anterior. Este caso de uso requiere la coherencia de los datos y almacena los datos en un formato relacional desnormalizado. Parte de la lógica anterior también se puede reutilizar y por eso es ideal para una amazona aurora compatible con mi secuela. Luego tenemos los microservicios de reparto. La función de reparto es la segunda función más utilizada en mascotas increíbles. Tiene un gran volumen de lecturas y escrituras y los tiempos de respuesta necesarios deberían ser de siete milisegundos, como recordará de la sesión de Williams. Este es un excelente caso de uso para una base de datos en memoria, como la de Brady en Elastic Cache. Y, por último, tenemos el catálogo, el catálogo actual, que consulta todo el inventario disponible y realiza una cuenta basada en el tipo de mascota, ya que Amazing Pets utiliza una base de datos relacional. Actualmente no pueden ofrecer una funcionalidad de búsqueda enriquecida y, por lo tanto, una de las tecnologías que pueden utilizar para el catálogo es el servicio Amazon Open Search. La búsqueda abierta puede ingerir fácilmente la búsqueda y acumular miles de millones de documentos. Ahora que hemos visto cómo se ve la arquitectura objetivo, hagamos otra prueba de rendimiento para ver cómo funciona la nueva arquitectura, como pueden ver, puedo agregar los parámetros a la U. R. L. Para empezar a usar el backend de microservicios y en este backend de microservicios, tengo aproximadamente el mismo número de mascotas si no más en comparación con la aplicación monolítica y la funcionalidad es exactamente la misma. Así puedo continuar y abrir la prueba para el backend de mis microservicios. Como puede ver, la prueba de rendimiento es la misma que la misma configuración que la prueba anterior y el recorrido del usuario es el mismo. Vamos a obtener el catálogo, añadir una tarjeta y enviar un pedido. Además, la configuración es la misma, con un total de 50 usuarios de hasta 10 minutos de duración y con un aumento de entre un minuto. Así que sigamos adelante y hagamos esta nueva prueba y echemos un vistazo a los resultados. Una vez finalizada la prueba. Como antes, aceleraré esta parte del vídeo hasta que se complete la prueba. Echemos un vistazo a estos resultados de un vistazo. Ya podemos ver que el rendimiento es mucho más consistente, ya que no hubo errores durante la prueba de rendimiento. Y, en general, el tiempo de respuesta promedio es de unos 160 milisegundos, 45 veces más rápido que nuestra aplicación monolítica. Así que echemos un vistazo a la radiografía y aquí podemos ver todas las interacciones entre los microservicios. Por ejemplo, podemos ver cómo la funcionalidad de enviar toda la funcionalidad abarca en realidad varios microservicios. Y aquí podemos ver las llamadas a la API para obtener el catálogo y agregar artículos al carrito. Ahora puedo ver los rastros específicos para profundizar en una sola solicitud de envío de pedido. Aquí podemos ver el desglose del tiempo empleado durante el envío o la transacción. Lo podemos ver bajo carga. Esta operación solo duró unos 300 milisegundos, lo que es 25 veces más rápido que el envío a la funcionalidad de la aplicación monolítica en las mismas condiciones. En la demostración, vimos cómo la arquitectura de microservicios es capaz de escalar bien para hacer frente al tráfico y proporcionar tiempos de respuesta consistentes. Otra característica de esta nueva arquitectura es que pueden lograr una disponibilidad mucho mayor. Si una de las bases de datos falla, solo uno de los microservicios se ve afectado y la aplicación puede seguir funcionando parcialmente si pasa a los microservicios. No solo podemos escalar y funcionar mejor, sino que también obtenemos una mayor disponibilidad. Por último, me gustaría mencionar brevemente los patrones de diseño que se usaron en esta composición. La primera es la notificación de eventos en esta nueva arquitectura. El microservicio del catálogo debe actualizarse cada vez que se añada o retire un artículo del inventario. Para implementar este patrón, utilizamos las transmisiones de dynamodb, que es una función de dynamodb que permite transmitir todos los cambios de la tabla. El segundo patrón es el patrón de la saga. Este patrón nos permite ejecutar transacciones comerciales en múltiples microservicios. En este ejemplo, el patrón cíclico se implementó mediante las funciones escalonadas de AWS y la transacción abarca el inventario, el pedido y los microservicios cat. Si desea obtener más información sobre los patrones de microservicios. Yo recomendaría ver la sesión titulada Construir microservicios brasileños utilizando patrones tolerantes a fallas. En esta sesión, analizamos cuáles son los requisitos de las aplicaciones modernas de hoy en día. A continuación, analizamos por qué los clientes pasaron de un enfoque único para todos a bases de datos especialmente diseñadas. Analizamos cómo puede elegir la base de datos adecuada para el trabajo correcto y vimos cómo puede ayudarlo a lograr una mayor escala, un mejor rendimiento y una mayor disponibilidad. En esta sesión cubrimos varios temas diferentes, pero el aprendizaje no tiene por qué terminar aquí. Le recomendamos que consulte nuestro contenido de formación y certificación. Ofrecemos más de 500 cursos digitales gratuitos que pueden ayudarlo a usted y a su equipo a desarrollar nuevas habilidades en la nube y a conocer los servicios más recientes. Y a medida que vaya desarrollando sus habilidades, considere la posibilidad de prepararse para una de nuestras 11 certificaciones de AWS. Puedes escanear los códigos QR en esta diapositiva para obtener más información. Gracias por asistir a esta charla. Nos encantaría escuchar sus comentarios para ayudarnos a mejorar la experiencia de las cumbres de AWS. Por lo tanto, recuerde completar la encuesta de la sesión. Gracias