{
  "sentences": [
    {
      "text": "Hi everybody",
      "startTime": "3.69",
      "endTime": "4.72"
    },
    {
      "text": "I'm leah and I'm Nikita and welcome to the data cloud live demo",
      "startTime": "4.73",
      "endTime": "9.25"
    },
    {
      "text": "If you're just joining us from this morning's keynote and spotlight you heard some of the latest innovations we launched Earth engine spark on google cloud postgres sequel interface for spanner and vertex Ai Workbench",
      "startTime": "9.29",
      "endTime": "23.0"
    },
    {
      "text": "All to help organizations solve their most complex data driven challenges in this live demo",
      "startTime": "23.01",
      "endTime": "29.65"
    },
    {
      "text": "We're going to take complex fragmented data systems and simplify them bringing together data on a massive scale to explore a real world scenario for climate and supply chain analytics",
      "startTime": "29.65",
      "endTime": "41.6"
    },
    {
      "text": "In order to do this, we're going to need the whole data team say hi everyone",
      "startTime": "41.61",
      "endTime": "46.54"
    },
    {
      "text": "Hello, I'm Brett hi I'm derek now a quick reminder",
      "startTime": "47.49",
      "endTime": "53.31"
    },
    {
      "text": "This demo is truly live and you can engage with us directly",
      "startTime": "53.32",
      "endTime": "56.58"
    },
    {
      "text": "So ask questions",
      "startTime": "56.6",
      "endTime": "57.92"
    },
    {
      "text": "Say hi in the chat window and hit those emojis",
      "startTime": "57.93",
      "endTime": "60.45"
    },
    {
      "text": "I think I see something coming in now",
      "startTime": "61.04",
      "endTime": "63.17"
    },
    {
      "text": "I see lots of hearts and fire a lot of people saying hello in the chat",
      "startTime": "63.18",
      "endTime": "67.65"
    },
    {
      "text": "Thanks everyone for joining us today",
      "startTime": "67.66",
      "endTime": "69.61"
    },
    {
      "text": "So if you can't see the emojis or the chat, just go back to the next event website and click on the blue, join the interactive experience button",
      "startTime": "70.38",
      "endTime": "79.2"
    },
    {
      "text": "Okay let's have a little fun with this today",
      "startTime": "79.21",
      "endTime": "84.65"
    },
    {
      "text": "You're actually joining us for our weekly stand up at symbol superstore a fictional US based grocery chain focused on sourcing from local producers",
      "startTime": "84.66",
      "endTime": "95.05"
    },
    {
      "text": "Like many different industries we need to bring together disparate data sources to build resilience specifically for us drought in the western U",
      "startTime": "95.09",
      "endTime": "104.24"
    },
    {
      "text": "S",
      "startTime": "104.24",
      "endTime": "104.52"
    },
    {
      "text": "Has impacted our producers and our supply chain has been disrupted with decreased shipments week over week",
      "startTime": "104.52",
      "endTime": "111.12"
    },
    {
      "text": "We need to better understand how to manage inventory and to prevent stock outs and ensure we can scale in both how we analyze information and how we run our transactions",
      "startTime": "111.54",
      "endTime": "122.12"
    },
    {
      "text": "Alright Team",
      "startTime": "122.67",
      "endTime": "123.53"
    },
    {
      "text": "So to address the supply and scale challenges that Nikita just mentioned",
      "startTime": "123.54",
      "endTime": "127.67"
    },
    {
      "text": "We have four different workloads",
      "startTime": "127.68",
      "endTime": "129.85"
    },
    {
      "text": "First I'm going to evaluate the best climate information to identify at risk producers then brad will mature our data pipelines to transform that data",
      "startTime": "129.86",
      "endTime": "141.76"
    },
    {
      "text": "Next derek will dig into scaling our transaction processing and finally Nikita will show how we're gaining new insights by evolving our data science capabilities",
      "startTime": "141.77",
      "endTime": "153.14"
    },
    {
      "text": "Let's get into it and let's keep hearing from all of you out",
      "startTime": "153.17",
      "endTime": "156.81"
    },
    {
      "text": "There are data pros leah you're up first",
      "startTime": "156.82",
      "endTime": "160.43"
    },
    {
      "text": "Great thanks Nikita",
      "startTime": "160.44",
      "endTime": "162.08"
    },
    {
      "text": "So in order to gain insight into our supply chain first I need to evaluate the risks",
      "startTime": "162.09",
      "endTime": "168.41"
    },
    {
      "text": "So I'm focusing on figuring out how drought impacts the very source of our grocery products and to do this I turn to google's platform for earth science data and analytics Earth Engine which has a huge catalog of satellite images for things like climate whether croplands and much more",
      "startTime": "168.42",
      "endTime": "187.22"
    },
    {
      "text": "There's currently over like 50 petabytes of data in the catalog plus more and more images are added each day",
      "startTime": "187.23",
      "endTime": "194.68"
    },
    {
      "text": "So let me just go ahead and bring up this cool little application that I built using the Earth engine code editor so I can walk you through the three datasets",
      "startTime": "195.35",
      "endTime": "203.93"
    },
    {
      "text": "We'll be using today first is gonna be crop data from the U",
      "startTime": "203.93",
      "endTime": "208.6"
    },
    {
      "text": "S",
      "startTime": "208.6",
      "endTime": "208.78"
    },
    {
      "text": "D",
      "startTime": "208.78",
      "endTime": "208.98"
    },
    {
      "text": "A",
      "startTime": "208.98",
      "endTime": "209.24"
    },
    {
      "text": "N",
      "startTime": "209.25",
      "endTime": "209.45"
    },
    {
      "text": "A",
      "startTime": "209.45",
      "endTime": "209.59"
    },
    {
      "text": "S",
      "startTime": "209.59",
      "endTime": "209.85"
    },
    {
      "text": "S",
      "startTime": "209.85",
      "endTime": "210.07"
    },
    {
      "text": "Program which I can grab right from the public data catalog by searching",
      "startTime": "210.07",
      "endTime": "214.05"
    },
    {
      "text": "So this data set is going to contain one image of the US for each year",
      "startTime": "214.83",
      "endTime": "220.91"
    },
    {
      "text": "Going back all the way to 1997 And each 10 m pixel in this image has actually been assigned a crop type",
      "startTime": "220.92",
      "endTime": "228.72"
    },
    {
      "text": "Let me just close out of this here",
      "startTime": "229.95",
      "endTime": "231.79"
    },
    {
      "text": "Bring you back to my app",
      "startTime": "231.79",
      "endTime": "233.11"
    },
    {
      "text": "So the second data set contains the outline of agricultural fields and we're gonna use Earth Engine to assign each one of these fields the crop type that is most prevalent among the cells that cover it",
      "startTime": "233.12",
      "endTime": "245.31"
    },
    {
      "text": "So in this view that I'm showing right here the pink fields are alfalfa and the dark green fields are almonds leah these visuals are super super helpful but could we export this data for analysis in other environments? Yeah I'm actually gonna push this into cloud storage and big query injustice sec",
      "startTime": "245.9",
      "endTime": "264.67"
    },
    {
      "text": "But first I want to add in some additional signals on drought",
      "startTime": "264.68",
      "endTime": "268.79"
    },
    {
      "text": "So the third data set that I'm using is a collection of both short and long term drought indicators meaning that we can see what drought looks like for each field over time",
      "startTime": "269.49",
      "endTime": "280.26"
    },
    {
      "text": "Now using data sets like these does require some deep subject matter expertise, expertise",
      "startTime": "280.27",
      "endTime": "286.34"
    },
    {
      "text": "So special thanks to our real world partners at climate engine who build solutions on top of earth engines A",
      "startTime": "286.35",
      "endTime": "293.31"
    },
    {
      "text": "P",
      "startTime": "293.31",
      "endTime": "293.52"
    },
    {
      "text": "I helping organizations ground their analytics projects with scientifically accepted methodologies",
      "startTime": "293.52",
      "endTime": "299.74"
    },
    {
      "text": "Okay, so you just saw how we use geospatial data and I want to know how you use it in your analysis",
      "startTime": "300.94",
      "endTime": "307.52"
    },
    {
      "text": "So go ahead and answer that poll so we can see Alright everyone",
      "startTime": "307.53",
      "endTime": "312.51"
    },
    {
      "text": "So with these layers in place we can start exploring drought risk",
      "startTime": "312.51",
      "endTime": "316.7"
    },
    {
      "text": "Let me just go ahead and zoom to this field and here I'm gonna show an almond orchard northeast of Modesto California and what we're looking at is the long term drought indicator",
      "startTime": "317.15",
      "endTime": "330.28"
    },
    {
      "text": "So this orange tint that you're seeing means that this field has experienced pretty high levels of drought over the last five years",
      "startTime": "330.29",
      "endTime": "338.29"
    },
    {
      "text": "Now if I go ahead and just zoom out a bit we can actually see that the entire central valley in California is pretty drought stressed",
      "startTime": "338.3",
      "endTime": "347.75"
    },
    {
      "text": "So my last step was to calculate drought risk for each of the fields I showed before and this will tell us which farms and produce types are potentially at risk for not meeting customer demand, which is just one consideration to inform symbols resilience strategy better yet we can incorporate this geography data with other spatial stuff like store and customer locations that are already inside a big query and anyone who knows me knows that I love big query",
      "startTime": "348.74",
      "endTime": "378.83"
    },
    {
      "text": "If you agree, let me see in the emojis",
      "startTime": "378.84",
      "endTime": "381.47"
    },
    {
      "text": "Alright, so the code editor has been great for interacting with Earth engine but making these calculations at scale requires a different approach",
      "startTime": "382.42",
      "endTime": "391.35"
    },
    {
      "text": "So I went ahead and created earth engine tasks for batch processing to run these calculations over all the data in five day increments for the past 10 years",
      "startTime": "391.36",
      "endTime": "402.04"
    },
    {
      "text": "I also set up a cloud function to run every five days going forward",
      "startTime": "402.71",
      "endTime": "406.67"
    },
    {
      "text": "So that will always have fresh data now",
      "startTime": "406.68",
      "endTime": "410.41"
    },
    {
      "text": "Just as a quick recap, we jumped into Earth engine to evaluate earth science data that indicates climate risk for our farm fields",
      "startTime": "410.42",
      "endTime": "418.06"
    },
    {
      "text": "Now we'll have fresh drought data available in cloud storage",
      "startTime": "418.1",
      "endTime": "422.33"
    },
    {
      "text": "So just think of the power of integrating huge amounts of specialized data, giving us a complete picture of supply risk for our business",
      "startTime": "422.34",
      "endTime": "431.08"
    },
    {
      "text": "Oh and I think I can see the poll results coming in now, it looks like lots of people are using geospatial data for all different kinds of things and if your answer wasn't in the poll just go ahead and let us know in the chat",
      "startTime": "432.12",
      "endTime": "445.91"
    },
    {
      "text": "So next up brad will transform and push this data into big query for geospatial analysis with our existing data So brad over to you",
      "startTime": "446.74",
      "endTime": "457.27"
    },
    {
      "text": "Okay, that was pretty cool",
      "startTime": "458.6",
      "endTime": "460.2"
    },
    {
      "text": "Yeah",
      "startTime": "460.2",
      "endTime": "460.37"
    },
    {
      "text": "Thanks",
      "startTime": "460.4",
      "endTime": "461.11"
    },
    {
      "text": "All right",
      "startTime": "461.99",
      "endTime": "462.97"
    },
    {
      "text": "So to gain more insight into how drought is impacting production, my main focus has been building out the data transformation pipeline to push farm field drought indicators from cloud storage into big query",
      "startTime": "463.01",
      "endTime": "474.61"
    },
    {
      "text": "Speaking of batch processing as you know to assist with inventory management, price optimization and product assortment, we use spark to standardize our large scale data processing and we use google cloud data products as our long running clusters for your data pros out there",
      "startTime": "475.08",
      "endTime": "491.61"
    },
    {
      "text": "We'd love to know how you're using spark today",
      "startTime": "491.62",
      "endTime": "493.73"
    },
    {
      "text": "So let us know while I go ahead and pull up the cloud council",
      "startTime": "493.74",
      "endTime": "496.16"
    },
    {
      "text": "So here is the data part cluster we currently use to schedule price park jobs and here I'm connected to a jupiter notebook running on the same cluster with some pie spark code",
      "startTime": "498.81",
      "endTime": "510.47"
    },
    {
      "text": "This code is typical boilerplate code you'd write to do basic data transformations in this case we are processing the earth engine files from cloud storage, performing type checking and mapping to ensure proper ingestion into big query using the spark big query connector",
      "startTime": "510.83",
      "endTime": "525.36"
    },
    {
      "text": "Hey brad",
      "startTime": "526.63",
      "endTime": "527.31"
    },
    {
      "text": "So this is pretty cool",
      "startTime": "527.31",
      "endTime": "528.66"
    },
    {
      "text": "But I think having a batch workflow that's scheduled on a continuously running cluster seems like it can be kind of wasteful",
      "startTime": "528.66",
      "endTime": "535.3"
    },
    {
      "text": "So is there any way we can make this more efficient? That's a fair point leah, there is still some overhead management here and for hardened batch cases like this, it would be preferred to have these jobs run on their own discrete resources",
      "startTime": "535.31",
      "endTime": "547.96"
    },
    {
      "text": "But good news with the new surveillance option for data product, we can submit a pie spark job without spitting up any infrastructure",
      "startTime": "548.85",
      "endTime": "555.48"
    },
    {
      "text": "These auto magic capabilities",
      "startTime": "555.66",
      "endTime": "558.19"
    },
    {
      "text": "I can spend more deaf time writing code and less time on managing infrastructure",
      "startTime": "558.2",
      "endTime": "562.32"
    },
    {
      "text": "All right brad",
      "startTime": "563.04",
      "endTime": "563.88"
    },
    {
      "text": "First off, I'm pretty sure that you just set me up for that and second you definitely made up that word",
      "startTime": "563.89",
      "endTime": "569.55"
    },
    {
      "text": "Automatic",
      "startTime": "569.56",
      "endTime": "570.42"
    },
    {
      "text": "Yeah, can I get the emoji love for that anyway",
      "startTime": "571.53",
      "endTime": "576.64"
    },
    {
      "text": "I'll now go ahead and export this notebook to a python file using N B convert",
      "startTime": "576.7",
      "endTime": "581.27"
    },
    {
      "text": "Okay",
      "startTime": "588.12",
      "endTime": "588.66"
    },
    {
      "text": "And next let's go and use the cloud sDK to submit a server list, Price park job we can use the data block aPI and call batches to submit a surveillance job",
      "startTime": "588.66",
      "endTime": "597.47"
    },
    {
      "text": "So I'm showing you here a spark job but I can also submit spark jobs written in scala, java are or sequel with auto provision and auto scale",
      "startTime": "601.29",
      "endTime": "612.17"
    },
    {
      "text": "No infrastructure configuration is needed",
      "startTime": "612.18",
      "endTime": "614.27"
    },
    {
      "text": "This helps those less familiar with how to fine tune their smart jobs to utilize its powerful distributed data processing model with these capabilities",
      "startTime": "614.66",
      "endTime": "622.62"
    },
    {
      "text": "There's no need to manually create into clusters",
      "startTime": "622.66",
      "endTime": "625.04"
    },
    {
      "text": "So once I've submitted the job I can show it listed in the surveillance spark console and I can click on the job to view its logs",
      "startTime": "626.39",
      "endTime": "632.92"
    },
    {
      "text": "Now, surveillance spark takes about a minute or so to auto provision the resources as well as start writing out log output",
      "startTime": "632.93",
      "endTime": "639.7"
    },
    {
      "text": "So what I'll go ahead and do here is show you the log output from a completed job that I ran earlier",
      "startTime": "639.71",
      "endTime": "644.39"
    },
    {
      "text": "So if we click in here we can see Okay",
      "startTime": "646.53",
      "endTime": "648.93"
    },
    {
      "text": "So I added some print statements into this job and here it's showing me that there's some short term job data that's processed some long term job data and then some geographical data as well now in addition to this, I can also show you the spark history server, which is where the more details of the spark job itself will be output ID once the job has been completed",
      "startTime": "648.93",
      "endTime": "670.58"
    },
    {
      "text": "So we can go back in the bug and then additionally we can also gain access to metadata via data, product meta store",
      "startTime": "670.58",
      "endTime": "676.29"
    },
    {
      "text": "Now, in addition to all of this, we are also looking into a new solution for creating long running clusters or a place where our infrastructure team can manage data park clusters",
      "startTime": "677.2",
      "endTime": "685.83"
    },
    {
      "text": "Now, fortunately we feel that spark on G K e fits our use case and lets us utilize our existing G K E infrastructure",
      "startTime": "685.84",
      "endTime": "692.65"
    },
    {
      "text": "So clearly it's been a busy week for me using spark survey list to create pipelines to push drought data into big query",
      "startTime": "694.07",
      "endTime": "700.47"
    },
    {
      "text": "But the efficiency improvements will gain by not needing to manage cluster overhead will be worth it",
      "startTime": "700.52",
      "endTime": "705.77"
    },
    {
      "text": "Now you can let me know in the chat if you're as excited about sparks surveillance as I am",
      "startTime": "705.88",
      "endTime": "710.05"
    },
    {
      "text": "Okay, let's see how everyone's using spark today looks like notebooks are pretty popular",
      "startTime": "710.2",
      "endTime": "717.76"
    },
    {
      "text": "Oh, an automation through airflow",
      "startTime": "719.42",
      "endTime": "721.97"
    },
    {
      "text": "That's cool too",
      "startTime": "721.97",
      "endTime": "722.78"
    },
    {
      "text": "Okay, great",
      "startTime": "723.63",
      "endTime": "724.47"
    },
    {
      "text": "Thanks so much brad",
      "startTime": "724.48",
      "endTime": "725.45"
    },
    {
      "text": "So now that we have greater insight into supply risks, we need to scale our transaction systems to handle more orders and allow us to understand the potential business impact of these climate risks while hopefully lowering costs",
      "startTime": "725.46",
      "endTime": "739.6"
    },
    {
      "text": "So this brings me to Derek our DB A Derek, you've been focusing on this effort",
      "startTime": "739.61",
      "endTime": "745.46"
    },
    {
      "text": "So can you let us know where you're at today? Yeah, absolutely leah",
      "startTime": "745.46",
      "endTime": "750.3"
    },
    {
      "text": "We have a new grocery chain that has struggled to maintain their on prem databases as they've grown",
      "startTime": "750.58",
      "endTime": "755.82"
    },
    {
      "text": "There's an opportunity to solve their underlying scaling problems with cloud spanner",
      "startTime": "755.93",
      "endTime": "760.26"
    },
    {
      "text": "I spent the last few weeks validating spanners ability to scale and the ease of maintenance while keeping strong consistency for this point of sale workload",
      "startTime": "760.86",
      "endTime": "768.67"
    },
    {
      "text": "I migrated some of the new change stores to spanner already using granular instance sizing I only provisioned a portion of a spanner node to handle the required load as we move the remainder of stores",
      "startTime": "769.94",
      "endTime": "781.08"
    },
    {
      "text": "We can easily scale up without downtime or app changes",
      "startTime": "781.08",
      "endTime": "784.13"
    },
    {
      "text": "Um quick question Derek, We've been really focused on reducing the cost and complexity of building scalable applications so I'm wondering how does adding spanner impact that effort? Yeah, that's a great question",
      "startTime": "785.04",
      "endTime": "797.89"
    },
    {
      "text": "Nikita, One way we've been doing this in other environments is to standardize on Postgres",
      "startTime": "797.89",
      "endTime": "802.62"
    },
    {
      "text": "Postgres is a well established open source database with an active ecosystem that our development and ops teams are already familiar with",
      "startTime": "803.2",
      "endTime": "810.01"
    },
    {
      "text": "I tried to get the team to add an elephant emoji",
      "startTime": "810.88",
      "endTime": "813.03"
    },
    {
      "text": "So y'all could show some love for postgres but anyway, spanner just announced a post rescue all interface",
      "startTime": "813.03",
      "endTime": "821.04"
    },
    {
      "text": "This gives us the benefits of spanner without having to completely retrain our application teams",
      "startTime": "821.31",
      "endTime": "825.89"
    },
    {
      "text": "Having a standard api for our data will help us maintain velocity for new features even as our database needs evolve here",
      "startTime": "826.26",
      "endTime": "834.44"
    },
    {
      "text": "Let me show you so I've connected into our spanner instance using the P SQL command line tool from here",
      "startTime": "834.49",
      "endTime": "843.21"
    },
    {
      "text": "I can explore the schema just like I would any other database, any other postgres database",
      "startTime": "843.22",
      "endTime": "848.67"
    },
    {
      "text": "Um you can see that the both the postgres data type and the spanner data type is available to the information schema",
      "startTime": "848.68",
      "endTime": "855.99"
    },
    {
      "text": "So this will make it familiar to anyone who has already knows postgres",
      "startTime": "857.18",
      "endTime": "864.35"
    },
    {
      "text": "Awesome",
      "startTime": "864.36",
      "endTime": "865.46"
    },
    {
      "text": "Thanks Derek, this is really cool",
      "startTime": "865.46",
      "endTime": "867.24"
    },
    {
      "text": "I'm really looking forward to the scalability that this is going to bring our team",
      "startTime": "867.25",
      "endTime": "870.78"
    },
    {
      "text": "Absolutely",
      "startTime": "872.07",
      "endTime": "873.13"
    },
    {
      "text": "And as a quick summary I highlighted how to spanner allows us to get started small and scale as needed using granular instant sizing and how the new postgres SQL interface reduces friction for our teams already familiar with postgres",
      "startTime": "873.29",
      "endTime": "886.59"
    },
    {
      "text": "Nikita and leah, you can treat the existing data is golden and I'll keep onboarding more stores",
      "startTime": "887.3",
      "endTime": "892.11"
    },
    {
      "text": "Uh Nikita, I believe you need this data for some of the big query analysis you were working on",
      "startTime": "893.33",
      "endTime": "898.49"
    },
    {
      "text": "You've been busy figuring out how to evolve our ability to make sense of all this data",
      "startTime": "898.5",
      "endTime": "903.29"
    },
    {
      "text": "Can you show us how that works? Yes, absolutely",
      "startTime": "903.54",
      "endTime": "906.21"
    },
    {
      "text": "I was hoping that you'd ask so to ensure that we're managing stock to meet customer demand",
      "startTime": "906.21",
      "endTime": "911.38"
    },
    {
      "text": "My focus this week was on evolving our data science capabilities for exploratory analysis",
      "startTime": "911.39",
      "endTime": "916.88"
    },
    {
      "text": "I combined the transactional data that Derek's been working on with the drought data that leah and brad pushed into big query this way we can gain insight into which products are most at risk of not meeting customer demand",
      "startTime": "916.9",
      "endTime": "929.55"
    },
    {
      "text": "So my first step was to integrate all of our transactional data within big query, primarily using federation with cloud, sequel and spanner",
      "startTime": "930.24",
      "endTime": "937.88"
    },
    {
      "text": "This provides a unified environment for aggregation and analysis where we can join transactions back to producer details and the associated drought risk scores",
      "startTime": "937.98",
      "endTime": "947.88"
    },
    {
      "text": "Now as you all know, we recently migrated to vertex ai Workbench which has really really helped with our basic compute and resource management",
      "startTime": "948.82",
      "endTime": "958.81"
    },
    {
      "text": "Quick question",
      "startTime": "960.27",
      "endTime": "961.33"
    },
    {
      "text": "Nikita is vertex Ai Workbench a notebook for vertex Ai that is an excellent question",
      "startTime": "961.33",
      "endTime": "966.87"
    },
    {
      "text": "Derek vertex Ai Workbench contains recently updated manage notebooks which bring forth more integrated data engineering capabilities into our data science environments so we can ingest and analyze data and deploy and manage ml models all from one spot",
      "startTime": "966.87",
      "endTime": "983.79"
    },
    {
      "text": "Now let me show you a little bit about what this looks like after I provisioned a new managed notebook",
      "startTime": "984.36",
      "endTime": "988.8"
    },
    {
      "text": "My first task was to analyze the demand on the high volume skews and for that I used the big query connector to view and query the sales data with vertex Ai Workbench, I can inspect big query metadata, preview tables and automate basic sequel construction entirely from my notebook environment",
      "startTime": "988.81",
      "endTime": "1009.08"
    },
    {
      "text": "Okay, it's my turn on the emojis",
      "startTime": "1009.77",
      "endTime": "1012.09"
    },
    {
      "text": "I want to see the fire emoji from all the data scientists out there who are as excited as I am about being able to access big query from the notebook interface",
      "startTime": "1012.1",
      "endTime": "1021.19"
    },
    {
      "text": "Look, I'm not the only one",
      "startTime": "1023.95",
      "endTime": "1025.97"
    },
    {
      "text": "Hey, nick",
      "startTime": "1026.69",
      "endTime": "1027.1"
    },
    {
      "text": "Ito hold on, sorry to interrupt your emoji fest but I see you're working out of the Lakes project but are able to pin other projects you have access to like the ops project, is that new? Yes, that's correct, brad, vertex ai Workbench actually enables me to interact with all services via my own identity",
      "startTime": "1027.1",
      "endTime": "1044.09"
    },
    {
      "text": "The big query plug in also provides some template id code to help build out queries and project results to a Panda's data frame",
      "startTime": "1044.79",
      "endTime": "1052.23"
    },
    {
      "text": "So here we can see it looks like I just need to refresh um sorry about that team",
      "startTime": "1052.24",
      "endTime": "1058.23"
    },
    {
      "text": "I'm just gonna refresh my jupiter lab instance here, I guess I had it open for too long and I guess while Nikita's doing that, like who uses jupiter now, let's see the fire emojis lighting up",
      "startTime": "1058.23",
      "endTime": "1068.48"
    },
    {
      "text": "I see",
      "startTime": "1070.08",
      "endTime": "1070.63"
    },
    {
      "text": "So now I personally use it a lot in my day today",
      "startTime": "1070.63",
      "endTime": "1076.46"
    },
    {
      "text": "All right, thank you so perfect",
      "startTime": "1076.47",
      "endTime": "1078.6"
    },
    {
      "text": "Now you can see a simple view of all transactions by the day of week um and vertex Workbench actually also allows me to launch different kernels entirely in the same instance",
      "startTime": "1078.61",
      "endTime": "1089.17"
    },
    {
      "text": "So brad, I think you were working out of a Pittsburgh notebook earlier, is that correct? Yeah, so data park clusters are also supported as a back end, as a part of spark on google cloud, we can access all supported kernels on the cluster including price park",
      "startTime": "1089.18",
      "endTime": "1102.44"
    },
    {
      "text": "Well for my analysis, I just needed a python kernel",
      "startTime": "1103.63",
      "endTime": "1106.64"
    },
    {
      "text": "So let me show you what's going on in this notebook and what I've been up to this week, you can see here that I've done a deep dive into the data, I've plotted the transaction volume, I've created a heat map of purchase counts across various departments and I've also plotted the short term drought index across various crop types like corn, dry beans, pears and rice",
      "startTime": "1106.64",
      "endTime": "1128.67"
    },
    {
      "text": "But my last task and the most important task was to map skews to suppliers and calculate a risk score based on the aggregate field data",
      "startTime": "1129.13",
      "endTime": "1137.32"
    },
    {
      "text": "So to do this, I started with our mapping table which you can see a sample of right here",
      "startTime": "1137.36",
      "endTime": "1142.12"
    },
    {
      "text": "This helped me to determine which farm fields actually source ingredients for a particular skew and then I calculated a weighted risk score that takes into account each product's demand and the associated farms overall drought risk and you can see each of these measurements in this data frame right here",
      "startTime": "1142.38",
      "endTime": "1158.67"
    },
    {
      "text": "Ultimately this score will help us to prioritize managing items where we're most at risk of not meeting customer demand",
      "startTime": "1159.03",
      "endTime": "1165.57"
    },
    {
      "text": "So as a quick summary, I used vertex ai Workbench manage notebooks to connect back to data accessible from big query and create a weighted risk score for each one of our products, combining both climate and demand data leah, I went ahead and put all of this back into big query just to keep it centralized awesome",
      "startTime": "1166.15",
      "endTime": "1184.64"
    },
    {
      "text": "Thanks so much Nikita that risk score is gonna be huge in helping our team understand supply risk",
      "startTime": "1184.65",
      "endTime": "1190.26"
    },
    {
      "text": "So to make sure the broader team has a trusted view of all this information",
      "startTime": "1190.93",
      "endTime": "1195.47"
    },
    {
      "text": "I started incorporating everything into a looker dashboard",
      "startTime": "1195.48",
      "endTime": "1199.41"
    },
    {
      "text": "Now with Looker we define our metrics like average risk using look ml lookers data model and Looker uses this to compile sequel queries and send them back to big query on our behalf so that our nontechnical users can explore the results of these data efforts",
      "startTime": "1199.42",
      "endTime": "1217.06"
    },
    {
      "text": "So let me show you this dashboard that I've been working on and first off you can see this custom map layer that I use to visualize drought risk across farm regions in the west and were able to take advantage of big queries, geospatial functions and drill from this aggregate view all the way to producer or even grocery product level",
      "startTime": "1217.55",
      "endTime": "1238.56"
    },
    {
      "text": "Let me show you so I'll drill to field I",
      "startTime": "1238.57",
      "endTime": "1242.02"
    },
    {
      "text": "D",
      "startTime": "1242.02",
      "endTime": "1242.72"
    },
    {
      "text": "And then I can jump right into Lookers explore to bring in some more fields like maybe I want to specifically look at products that are at risk in this region where we're quickly expanding",
      "startTime": "1243.25",
      "endTime": "1255.43"
    },
    {
      "text": "Making all this data accessible to the broader team is really important",
      "startTime": "1259.62",
      "endTime": "1263.21"
    },
    {
      "text": "So can we make sure that the marketing team is aware of this so they know how to hold off on coupons or advertisements for these products",
      "startTime": "1263.21",
      "endTime": "1270.1"
    },
    {
      "text": "Yeah actually we can set up a schedule from lookers so that the regional marketing teams are always notified if new products seem to go at risk",
      "startTime": "1270.2",
      "endTime": "1278.89"
    },
    {
      "text": "So putting this all together, we used Earth engine to process new earth science data signals",
      "startTime": "1279.5",
      "endTime": "1285.33"
    },
    {
      "text": "We use spark to efficiently transform geospatial data and push drought indicators into big query spanner to scale our transaction systems, ensuring we have the infrastructure to handle future growth and vertex Ai Workbench Plus Looker backed by the power of big query to evolve our data science capabilities and surface important trends back to key decision makers",
      "startTime": "1285.34",
      "endTime": "1310.53"
    },
    {
      "text": "So with integrations across these services, anyone is able to explore and take action on insights that combine climate data and transactions",
      "startTime": "1310.54",
      "endTime": "1320.42"
    },
    {
      "text": "Now we can understand where products may go out of stock due to increasing drought conditions and identify areas to build resilience against changes in our climate",
      "startTime": "1321.07",
      "endTime": "1331.12"
    },
    {
      "text": "So with this geospatial information we're given a whole new set of data so that we can not only be considerate of our customers but also find ways to be more considerate of our planet and with that it looks like we're right about at time",
      "startTime": "1331.88",
      "endTime": "1346.59"
    },
    {
      "text": "So thank you so much for joining us today as we've shown how google cloud can offer a world class experience for creating a scalable unified data platform and a special thanks to my colleagues Nikita for showing us vertex ai Workbench",
      "startTime": "1346.6",
      "endTime": "1363.2"
    },
    {
      "text": "Derek for introducing us to spanner and its postgres interoperability and brad for walking us through spark on google cloud",
      "startTime": "1363.21",
      "endTime": "1371.36"
    },
    {
      "text": "And thank you leah for showing us Looker and Earth Engine",
      "startTime": "1371.59",
      "endTime": "1375.15"
    },
    {
      "text": "Last but certainly not least",
      "startTime": "1375.16",
      "endTime": "1377.26"
    },
    {
      "text": "Thank you all out there so much for your engagement",
      "startTime": "1377.27",
      "endTime": "1379.94"
    },
    {
      "text": "We love those emojis and seeing all of your comments in the chat",
      "startTime": "1379.95",
      "endTime": "1383.45"
    },
    {
      "text": "So stay tuned for our live Q and A",
      "startTime": "1383.46",
      "endTime": "1385.55"
    },
    {
      "text": "Which is going to cover everything from our spotlight through this demo",
      "startTime": "1385.55",
      "endTime": "1389.19"
    },
    {
      "text": "Thank you",
      "startTime": "1389.2",
      "endTime": "1390.48"
    },
    {
      "text": "Thanks everyone",
      "startTime": "1390.48",
      "endTime": "1392.02"
    },
    {
      "text": ""
    }
  ],
  "phrases": []
}